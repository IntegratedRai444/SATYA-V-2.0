import mediapipe as mp
import numpy as np

mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils

# Helper functions for blink and pose detection

def eye_aspect_ratio(landmarks, left_indices, right_indices):
    # Compute EAR for both eyes
    def _ear(eye):
        A = np.linalg.norm(eye[1] - eye[5])
        B = np.linalg.norm(eye[2] - eye[4])
        C = np.linalg.norm(eye[0] - eye[3])
        return (A + B) / (2.0 * C)
    left_eye = np.array([landmarks[i] for i in left_indices])
    right_eye = np.array([landmarks[i] for i in right_indices])
    left_ear = _ear(left_eye)
    right_ear = _ear(right_eye)
    return (left_ear + right_ear) / 2.0

def get_pose(landmarks):
    # Use nose, left eye, right eye, left ear, right ear for basic pose estimation
    # Return yaw, pitch, roll (stub, not full 3D pose)
    # For simplicity, return zeros (implement with solvePnP for real use)
    return 0.0, 0.0, 0.0

def predict_webcam_liveness(arr):
    """
    Takes a preprocessed image array and returns (label, confidence, explanation).
    Uses mediapipe FaceMesh for blink and pose detection.
    """
    # Convert arr to uint8 image
    img = (arr * 255).astype('uint8')
    if img.shape[-1] == 1:
        img = np.repeat(img, 3, axis=-1)
    results = None
    explanation = []
    blink_detected = False
    blink_count = 0
    yaw, pitch, roll = 0.0, 0.0, 0.0
    spoof = False
    try:
        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:
            results = face_mesh.process(img)
            if results.multi_face_landmarks:
                landmarks = results.multi_face_landmarks[0]
                h, w = img.shape[:2]
                coords = [(int(lm.x * w), int(lm.y * h)) for lm in landmarks.landmark]
                # EAR indices for left/right eyes (mediapipe)
                left_eye_idx = [33, 160, 158, 133, 153, 144]
                right_eye_idx = [362, 385, 387, 263, 373, 380]
                ear = eye_aspect_ratio(coords, left_eye_idx, right_eye_idx)
                explanation.append(f"EAR: {ear:.2f}")
                if ear < 0.18:
                    blink_detected = True
                    blink_count = 1
                # Pose estimation (stub)
                yaw, pitch, roll = get_pose(coords)
                explanation.append(f"Pose (yaw, pitch, roll): {yaw:.2f}, {pitch:.2f}, {roll:.2f}")
                # Simple spoof heuristic: if face is detected and EAR is reasonable, assume not spoofed
                spoof = False if ear > 0.1 else True
            else:
                explanation.append("No face detected.")
                spoof = True
    except Exception as e:
        explanation.append(f"Mediapipe error: {e}")
        spoof = True
    # Liveness decision
    if not spoof and blink_detected:
        label = 'REAL'
        confidence = 98.0
        explanation.append("Blink detected, face present, pose normal.")
    elif not spoof:
        label = 'REAL'
        confidence = 90.0
        explanation.append("Face present, no blink detected.")
    else:
        label = 'FAKE'
        confidence = 60.0
        explanation.append("Possible spoof: no face or abnormal EAR.")
    return label, confidence, explanation 