import { Router, Request, Response } from 'express';
import multer, { FileFilterCallback } from 'multer';

// Interface for multer file in fileFilter
interface MulterFile {
  fieldname: string;
  originalname: string;
  encoding: string;
  mimetype: string;
  size: number;
  destination: string;
  filename: string;
  path: string;
  buffer: Buffer;
}
import path from 'path';
import { validateRequest } from '../middleware/validate-request';
import { logger } from '../config/logger';
import { enhancedPythonBridge } from '../config/python-bridge';
import { validateJobId } from '../middleware/validate-job-id';
import { createAnalysisJob, updateAnalysisJobWithResults } from './history';
import { errorResponse } from '../utils/apiResponse';
import FormData from 'form-data';
import { randomUUID } from 'crypto';
import { AuthenticatedRequest } from '../types/auth';
import { requireAuth } from '../middleware/auth.middleware';
import webSocketManager from '../services/websocket-manager';
import jobManager from '../services/job-manager';
import { setImmediate } from 'timers';
import { requestIdMiddleware, getRequestId } from '../middleware/request-id';
import { supabaseAdmin } from '../config/supabase';
import { analysisRateLimit, incrementConcurrentJobs } from '../middleware/rate-limiter';
import { createFallbackMiddleware } from '../middleware/fallback-middleware';
import { recordJobStart } from './system-metrics';
import { captureError } from '../services/error-monitor';

type AnalysisModality = 'image' | 'video' | 'audio' | 'text';

// Helper function to send job progress updates
const sendJobProgress = (userId: string, jobId: string, stage: string, progress: number) => {
  webSocketManager.sendEventToUser(userId, {
    type: 'JOB_PROGRESS',
    jobId,
    timestamp: Date.now(),
    data: {
      stage,
      progress
    }
  });
};

const router = Router();

// Apply request ID middleware to all routes
router.use(requestIdMiddleware);

// Apply authentication middleware to all routes
router.use(...requireAuth);

// Apply rate limiting to analysis endpoints  
router.use('/image', analysisRateLimit);
router.use('/video', analysisRateLimit);
router.use('/audio', analysisRateLimit);
router.use('/text', analysisRateLimit);

// Apply fallback middleware for service failures
const fallbackMiddleware = createFallbackMiddleware({
  pythonFailureMessage: 'AI analysis service temporarily unavailable. Please try again later.',
  databaseFailureMessage: 'Database temporarily unavailable. Your analysis is still being processed.',
  webSocketFailureMessage: 'Real-time updates temporarily unavailable. Results will be available upon completion.'
});

router.use(fallbackMiddleware);

// Configure multer for secure file uploads with memory storage
const storage = multer.memoryStorage();

// Define allowed file types with their magic numbers and size limits (in bytes)
const MAX_FILE_SIZE = 50 * 1024 * 1024; // 50MB
const ALLOWED_FILE_TYPES = {
  'image/jpeg': { 
    ext: '.jpg', 
    magic: [0xFF, 0xD8, 0xFF],
    maxSize: 10 * 1024 * 1024 // 10MB for JPEG
  },
  'image/jpg': { 
    ext: '.jpg', 
    magic: [0xFF, 0xD8, 0xFF],
    maxSize: 10 * 1024 * 1024 // 10MB for JPEG
  },
  'image/png': { 
    ext: '.png', 
    magic: [0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A],
    maxSize: 10 * 1024 * 1024 // 10MB for PNG
  },
  'image/webp': { 
    ext: '.webp', 
    magic: [0x52, 0x49, 0x46, 0x46, 0, 0, 0, 0x57, 0x45, 0x42, 0x50],
    maxSize: 10 * 1024 * 1024 // 10MB for WebP
  },
  'video/mp4': { 
    ext: '.mp4', 
    magic: [0x00, 0x00, 0x00, 0x18, 0x66, 0x74, 0x79, 0x70],
    maxSize: MAX_FILE_SIZE
  },
  'video/webm': { 
    ext: '.webm', 
    magic: [0x1A, 0x45, 0xDF, 0xA3],
    maxSize: MAX_FILE_SIZE
  },
  'video/avi': { 
    ext: '.avi', 
    magic: [0x52, 0x49, 0x46, 0x46],
    maxSize: MAX_FILE_SIZE
  },
  'video/mov': { 
    ext: '.mov', 
    magic: [0x6D, 0x6F, 0x6F, 0x76],
    maxSize: MAX_FILE_SIZE
  },
  'video/mkv': { 
    ext: '.mkv', 
    magic: [0x1A, 0x45, 0xDF, 0xA3],
    maxSize: MAX_FILE_SIZE
  },
  'audio/mp3': { 
    ext: '.mp3', 
    magic: [0x49, 0x44, 0x33],
    maxSize: MAX_FILE_SIZE
  },
  'audio/wav': { 
    ext: '.wav', 
    magic: [0x52, 0x49, 0x46, 0x46],
    maxSize: MAX_FILE_SIZE
  },
  'audio/mpeg': { 
    ext: '.mp3', 
    magic: [0x49, 0x44, 0x33],
    maxSize: MAX_FILE_SIZE
  },
  'audio/ogg': { 
    ext: '.ogg', 
    magic: [0x4F, 0x67, 0x67, 0x53],
    maxSize: MAX_FILE_SIZE
  },
} as const;

type AllowedMimeType = keyof typeof ALLOWED_FILE_TYPES;

// Function to check file magic numbers
const checkMagicNumbers = (buffer: Buffer, expectedMagic: readonly number[]): boolean => {
  if (buffer.length < expectedMagic.length) return false;
  
  for (let i = 0; i < expectedMagic.length; i++) {
    if (buffer[i] !== expectedMagic[i]) {
      return false;
    }
  }
  return true;
};

const upload = multer({
  storage,
  limits: {
    fileSize: MAX_FILE_SIZE,
    files: 1,
    fields: 5, // Limit number of form fields
    headerPairs: 20, // Limit number of header key-value pairs
  },
  fileFilter: (req: Request, file: MulterFile, cb: FileFilterCallback) => {
    try {
      // Validate MIME type
      const mimeType = file.mimetype as AllowedMimeType;
      const fileConfig = ALLOWED_FILE_TYPES[mimeType];
      
      if (!fileConfig) {
        return cb(new Error(`Unsupported file type: ${file.mimetype}. Allowed types: ${Object.keys(ALLOWED_FILE_TYPES).join(', ')}`));
      }

      // Validate file extension
      const ext = path.extname(file.originalname).toLowerCase();
      if (ext !== fileConfig.ext) {
        return cb(new Error(`Invalid file extension. Expected ${fileConfig.ext} for ${file.mimetype}`));
      }

      // Validate filename (allow common valid characters)
      const invalidChars = /[<>:"/\\|?*\x00-\x1F]/;
      const sanitizedFilename = path.basename(file.originalname).replace(invalidChars, '');
      if (sanitizedFilename !== file.originalname) {
        return cb(new Error('Invalid characters in filename'));
      }

      // Check for path traversal
      if (file.originalname.includes('..') || path.isAbsolute(file.originalname)) {
        return cb(new Error('Invalid file path'));
      }

      // Check file size against type-specific limit
      if (file.size > fileConfig.maxSize) {
        return cb(new Error(`File too large. Maximum size: ${formatBytes(fileConfig.maxSize)}`));
      }

      // Additional security checks
      cb(null, true);

      // For small files, we can check magic numbers immediately
      if (file.size > 0 && file.size < fileConfig.magic.length) {
        return cb(new Error('File too small to determine type'));
      }

      // Check magic numbers for files that have enough data
      if (file.size >= fileConfig.magic.length) {
        const magic = file.buffer.slice(0, fileConfig.magic.length);
        if (!checkMagicNumbers(magic, fileConfig.magic)) {
          return cb(new Error('Invalid file signature'));
        }
      }

      cb(null, true);
    } catch (error: unknown) {
      const err = error instanceof Error ? error : new Error('Unknown error during file validation');
      logger.error('File validation error', { 
        error: err.message, 
        filename: file.originalname,
        mimetype: file.mimetype,
        size: file.size
      });
      cb(err);
    }
  },
});

// Helper function to format bytes
function formatBytes(bytes: number, decimals = 2): string {
  if (bytes === 0) return '0 Bytes';
  const k = 1024;
  const dm = decimals < 0 ? 0 : decimals;
  const sizes = ['Bytes', 'KB', 'MB', 'GB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
}

// Helper function to handle analysis errors with proper typing and security
const handleAnalysisError = async (error: unknown, res: Response, jobId?: string, context: Record<string, unknown> = {}) => {
  // Create a safe error object
  const safeError = error instanceof Error 
    ? { 
        name: error.name,
        message: error.message,
        stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
      }
    : { message: 'An unknown error occurred' };
  
  // Extract Python bridge error details if available
  const pythonError = error && typeof error === 'object' && 'details' in error ? error.details as {
    code?: string;
    message?: string;
    status?: number;
    timestamp?: string;
  } : undefined;
  
  // Determine appropriate status code and message
  let statusCode = 500;
  let errorCode = 'ANALYSIS_ERROR';
  let message = 'Analysis failed. Please try again.';
  
  if (pythonError?.code) {
    switch (pythonError.code) {
      case 'PYTHON_DOWN':
        statusCode = 503;
        errorCode = 'AI_ENGINE_UNAVAILABLE';
        message = 'AI engine temporarily unavailable. Please try again later.';
        break;
      case 'ANALYSIS_TIMEOUT':
        statusCode = 504;
        errorCode = 'ANALYSIS_TIMEOUT';
        message = 'Analysis took too long. Please try with a smaller file.';
        break;
      case 'INVALID_REQUEST':
      case 'VALIDATION_ERROR':
        statusCode = 400;
        errorCode = 'INVALID_FILE';
        message = 'Invalid file format or corrupted file.';
        break;
      case 'NETWORK_ERROR':
        statusCode = 503;
        errorCode = 'NETWORK_ERROR';
        message = 'Network connection to AI service failed.';
        break;
      default:
        statusCode = 502;
        errorCode = 'AI_SERVICE_ERROR';
        message = 'AI service error occurred.';
    }
  }
  
  // If we have a jobId, update it with failed status
  if (jobId) {
    try {
      await updateAnalysisJobWithResults(jobId, {
        status: 'failed',
        error_message: pythonError?.message || safeError.message
      });
    } catch (dbError) {
      logger.error('Failed to update job status:', dbError);
      captureError(dbError instanceof Error ? dbError : new Error(String(dbError)), {
        jobId,
        endpoint: 'analysis',
        method: 'handleAnalysisError'
      }, 'high');
    }
  }
  
  // Log the error with context (redacting sensitive data)
  logger.error('Analysis error', {
    ...safeError,
    ...context,
    pythonError,
    jobId,
    // Redact sensitive data from context
    headers: undefined,
    body: undefined,
    file: context.file ? '[REDACTED]' : undefined,
  });

  // Return a sanitized error response
  return res.status(statusCode).json({
    success: false,
    code: errorCode,
    message,
    details: pythonError || undefined,
    // Only include error details in development
    ...(process.env.NODE_ENV === 'development' && { 
      error: safeError.message,
      pythonError 
    }),
    // Include a request ID for support
    requestId: res.locals.requestId,
    ...(jobId && { jobId })
  });
};

// Helper function to extract JWT token from request
const extractTokenFromRequest = (req: AuthenticatedRequest): string | null => {
  // Check Authorization header first
  const authHeader = req.headers.authorization;
  if (authHeader && authHeader.startsWith('Bearer ')) {
    return authHeader.substring(7);
  }
  
  // Check cookies
  if (req.cookies?.['sb-access-token']) {
    return req.cookies['sb-access-token'];
  }
  
  return null;
};

// Image analysis endpoint
router.post(
  '/image',
  ...requireAuth,
  analysisRateLimit,
  upload.single('file'),
  validateRequest([]),
  async (req: AuthenticatedRequest, res: Response) => {
    const type = 'image';
    const correlationId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const file = req.file;
    const userId = req.user?.id;\n    const userToken = extractTokenFromRequest(req);
    const userToken = extractTokenFromRequest(req);

    logger.info(`[ROUTE] Incoming ${type} analysis request`, {
      correlationId,
      type,
      userId,
      filename: file?.originalname,
      fileSize: file?.size,
    });

    // Increment concurrent job counter
    if (userId) {
      incrementConcurrentJobs(userId);
    }

    // Record job start for metrics
    recordJobStart();

    try {
      // Validate authentication
      if (!userId) {
        logger.warn(`[AUTH] User not authenticated for ${type} analysis`, { correlationId });
        return res.status(401).json({
          success: false,
          message: 'Authentication required'
        });
      }

      // Validate file
      if (!file) {
        logger.warn(`[IMAGE] No file uploaded`, { correlationId });
        return res.status(400).json({
          success: false,
          message: 'No file uploaded',
        });
      }

      logger.info(`[IMAGE] File parsed successfully`, {
        correlationId,
        filename: file.originalname,
        mimetype: file.mimetype,
        size: file.size
      });

      // Create job with pure UUID (no prefix for database compatibility)
      const jobId = randomUUID();
      logger.info('JOB_CREATED', { jobId, type: 'image' });
      
      // Create job in database BEFORE sending response
      let job: { id: string } | null;
      try {
        job = await createAnalysisJob(userId || '', {
          modality: type as AnalysisModality,
          filename: file.originalname,
          mime_type: file.mimetype,
          size_bytes: file.size,
          metadata: {
            originalName: file.originalname,
            mimeType: file.mimetype,
            size: file.size,
          },
        }, jobId); // ðŸ”¥ CRITICAL FIX: Pass jobId to ensure consistency

        logger.info(`[ANALYSIS JOB] Created job ${jobId}`, {
          correlationId,
          jobId,
          type,
        });

        // Send job started event via WebSocket
        if (userId) {
          webSocketManager.sendJobUpdate(userId, jobId, 'processing', 0, 'Job started and queued for processing');
        }
      } catch (dbError) {
        logger.error(`[JOB CREATION FAILED] ${jobId}`, { error: dbError, correlationId });
        return res.status(500).json({
          success: false,
          error: 'Failed to create analysis job'
        });
      }

      // Process in background
      setImmediate(async () => {
        try {
          // Send progress update
          if (userId) {
            sendJobProgress(userId, jobId, 'uploading', 10);
          }

          // Forward to Python service for inference only
          if (!file || !file.buffer) {
            throw new Error('File is required and must have buffer data');
          }
          
          const formData = new FormData();
          formData.append('file', file.buffer, {
            filename: file.originalname,
            contentType: file.mimetype,
          });
          formData.append('job_id', jobId);
          formData.append('user_id', userId || '');

          if (userId) {
            sendJobProgress(userId, jobId, 'analyzing', 30);
          }

          const pythonResponse = await enhancedPythonBridge.request({
        method: 'POST',
        url: `/api/v2/analysis/unified/${type}`,
        data: formData,
        timeout: 300000, // 5 minutes\n            userToken: userToken || undefined
        userToken: userToken || undefined
      }) as {
        data: {
              confidence: number;
              is_deepfake: boolean;
              model_name: string;
              model_version: string;
              analysis_data: Record<string, unknown>;
              proof: Record<string, unknown>;
            };
          };

          if (userId) {
            sendJobProgress(userId, jobId, 'processing', 70);
          }

          // Python returns inference-only payload
          const inferenceResult = pythonResponse.data;
          
          // [PYTHON RESULT] - Critical observability point
          logger.info('[PYTHON RESULT]', {
            jobId,
            status: 'success',
            confidence: inferenceResult.confidence,
            is_deepfake: inferenceResult.is_deepfake,
            model_name: inferenceResult.model_name
          });
          
          // Node owns the job lifecycle - ATOMIC GUARD for finalization
          if (job?.id) {
            try {
              await updateAnalysisJobWithResults(job.id, {
                status: 'completed',
                confidence: inferenceResult.confidence,
                is_deepfake: inferenceResult.is_deepfake,
                model_name: inferenceResult.model_name,
                model_version: inferenceResult.model_version,
                analysis_data: inferenceResult.analysis_data,
                proof_json: inferenceResult.proof,
              });
              
              // [JOB FINALIZED] - Critical observability point
              logger.info('[JOB FINALIZED]', {
                jobId: job.id,
                status: 'completed',
                confidence: inferenceResult.confidence
              });
              
            } catch (finalizationError) {
              // FINALIZATION FAILURE - Force fail state
              logger.error('[FINALIZATION FAILURE]', {
                jobId: job.id,
                error: finalizationError
              });
              
              await updateAnalysisJobWithResults(job.id, {
                status: 'failed',
                error_message: 'Finalization failed: ' + String(finalizationError)
              });
              
              throw finalizationError;
            }
          } else {
            logger.error('[NO JOB ID]', { jobId, pythonResponse: 'success' });
          }

          if (userId) {
            sendJobProgress(userId, jobId, 'completed', 100);

            // Send WebSocket event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_COMPLETED',
              jobId,
              timestamp: Date.now(),
              data: {
                status: 'completed',
                confidence: inferenceResult.confidence,
                is_deepfake: inferenceResult.is_deepfake,
                model_name: inferenceResult.model_name,
                model_version: inferenceResult.model_version,
              },
            });
          }

          logger.info(`[ANALYSIS COMPLETED] Job ${jobId} finished successfully`, {
            correlationId,
            jobId,
            type,
            confidence: inferenceResult.confidence,
            is_deepfake: inferenceResult.is_deepfake,
          });

        } catch (error) {
          // Handle analysis error
          const errorMessage = error && typeof error === 'object' && 'response' in error 
            ? ((error as unknown) as { response: { data?: { detail?: string } } }).response?.data?.detail || ((error as unknown) as Error).message || 'Analysis failed'
            : ((error as unknown) as Error).message || 'Analysis failed';
          
          await updateAnalysisJobWithResults(job?.id || '', {
            status: 'failed',
            error_message: errorMessage || 'Analysis failed',
          });

          if (userId) {
            // Send WebSocket error event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_FAILED',
              jobId,
              timestamp: Date.now(),
              data: {
                error: errorMessage,
              },
            });
          }

          logger.error(`[ANALYSIS FAILED] Job ${jobId} failed`, {
            correlationId,
            jobId,
            type,
            error: errorMessage,
          });
        }
      });

    } catch (error) {
      logger.error(`[ANALYSIS ERROR] ${type} analysis failed`, {
        correlationId,
        type,
        error: (error as Error).message,
      });
      
      return errorResponse(res, {
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Internal server error',
      }, 500);
    }
  }
);

// Video analysis endpoint
router.post(
  '/video',
  upload.single('file'),
  validateRequest([]),
  async (req: AuthenticatedRequest, res: Response) => {
    const type = 'video';
    const correlationId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const file = req.file;
    const userId = req.user?.id;\n    const userToken = extractTokenFromRequest(req);
    const userToken = extractTokenFromRequest(req);

    logger.info(`[ANALYSIS REQUEST] ${type} analysis started`, {
      correlationId,
      type,
      userId,
      filename: file?.originalname,
      fileSize: file?.size,
    });

    try {
      // Validate file
      if (!file) {
        return res.status(400).json({
          success: false,
          message: 'No file uploaded',
        });
      }

      // Create job with pure UUID (no prefix for database compatibility)
      const jobId = randomUUID();
      logger.info('JOB_CREATED', { jobId, type: 'video' });
      
      // Create job in database
      let job: { id: string } | null;
      try {
        job = await createAnalysisJob(userId || '', {
          modality: type as AnalysisModality,
          filename: file.originalname,
          mime_type: file.mimetype,
          size_bytes: file.size,
          metadata: {
            originalName: file.originalname,
            mimeType: file.mimetype,
            size: file.size,
          },
        }, jobId); // CRITICAL FIX: Pass jobId to ensure consistency

        logger.info(`[ANALYSIS JOB] Created job ${jobId}`, {
          correlationId,
          jobId,
          type,
        });

        // Send job started event via WebSocket
        if (userId) {
          webSocketManager.sendJobUpdate(userId, jobId, 'processing', 0, 'Job started and queued for processing');
        }
      } catch (dbError) {
        logger.error(`[JOB CREATION FAILED] ${jobId}`, { error: dbError, correlationId });
        return res.status(500).json({
          success: false,
          error: 'Failed to create analysis job' // CRITICAL FIX: Remove job_id from error response to prevent frontend polling for non-existent jobs
        });
      }

    // Send immediate response with job_id only after successful DB creation
      res.status(202).json({
        success: true,
        job_id: jobId,
        status: 'processing',
      });

      // Process in background
      setImmediate(async () => {
        try {
          // Send progress update
          if (userId) {
            sendJobProgress(userId, jobId, 'uploading', 10);
          }

          // Forward to Python service for inference only
          if (!file || !file.buffer) {
            throw new Error('File is required and must have buffer data');
          }
          
          const formData = new FormData();
          formData.append('file', file.buffer, {
            filename: file.originalname,
            contentType: file.mimetype,
          });
          formData.append('job_id', jobId);
          formData.append('user_id', userId || '');

          if (userId) {
            sendJobProgress(userId, jobId, 'analyzing', 30);
          }

          const pythonResponse = await enhancedPythonBridge.request({
            method: 'POST',
            url: `/api/v2/analysis/unified/${type}`,
            data: formData,
            timeout: 300000, // 5 minutes\n            userToken: userToken || undefined
          }) as {
            data: {
              confidence: number;
              is_deepfake: boolean;
              model_name: string;
              model_version: string;
              analysis_data: Record<string, unknown>;
              proof: Record<string, unknown>;
            };
          };

          if (userId) {
            sendJobProgress(userId, jobId, 'processing', 70);
          }

          // Python returns inference-only payload
          const inferenceResult = pythonResponse.data;
          
          // [PYTHON RESULT] - Critical observability point
          logger.info('[PYTHON RESULT]', {
            jobId,
            status: 'success',
            confidence: inferenceResult.confidence,
            is_deepfake: inferenceResult.is_deepfake,
            model_name: inferenceResult.model_name
          });
          
          // Node owns the job lifecycle - ATOMIC GUARD for finalization
          if (job?.id) {
            try {
              await updateAnalysisJobWithResults(job.id, {
                status: 'completed',
                confidence: inferenceResult.confidence,
                is_deepfake: inferenceResult.is_deepfake,
                model_name: inferenceResult.model_name,
                model_version: inferenceResult.model_version,
                analysis_data: inferenceResult.analysis_data,
                proof_json: inferenceResult.proof,
              });
              
              // [JOB FINALIZED] - Critical observability point
              logger.info('[JOB FINALIZED]', {
                jobId: job.id,
                status: 'completed',
                confidence: inferenceResult.confidence
              });
              
            } catch (finalizationError) {
              // FINALIZATION FAILURE - Force fail state
              logger.error('[FINALIZATION FAILURE]', {
                jobId: job.id,
                error: finalizationError
              });
              
              await updateAnalysisJobWithResults(job.id, {
                status: 'failed',
                error_message: 'Finalization failed: ' + String(finalizationError)
              });
              
              throw finalizationError;
            }
          } else {
            logger.error('[NO JOB ID]', { jobId, pythonResponse: 'success' });
          }

          if (userId) {
            sendJobProgress(userId, jobId, 'completed', 100);

            // Send WebSocket event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_COMPLETED',
              jobId,
              timestamp: Date.now(),
              data: {
                status: 'completed',
                confidence: inferenceResult.confidence,
                is_deepfake: inferenceResult.is_deepfake,
                model_name: inferenceResult.model_name,
                model_version: inferenceResult.model_version,
              },
            });
          }

          logger.info(`[ANALYSIS COMPLETED] Job ${jobId} finished successfully`, {
            correlationId,
            jobId,
            type,
            confidence: inferenceResult.confidence,
            is_deepfake: inferenceResult.is_deepfake,
          });

        } catch (error) {
          // Handle analysis error
          const errorMessage = error && typeof error === 'object' && 'response' in error 
            ? ((error as unknown) as { response: { data?: { detail?: string } } }).response?.data?.detail || ((error as unknown) as Error).message || 'Analysis failed'
            : ((error as unknown) as Error).message || 'Analysis failed';
          
          await updateAnalysisJobWithResults(job?.id || '', {
            status: 'failed',
            error_message: errorMessage || 'Analysis failed',
          });

          if (userId) {
            // Send WebSocket error event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_FAILED',
              jobId,
              timestamp: Date.now(),
              data: {
                error: errorMessage,
              },
            });
          }

          logger.error(`[ANALYSIS FAILED] Job ${jobId} failed`, {
            correlationId,
            jobId,
            type,
            error: errorMessage,
          });
        }
      });

    } catch (error) {
      logger.error(`[ANALYSIS ERROR] ${type} analysis failed`, {
        correlationId,
        type,
        error: (error as Error).message,
      });
      
      return errorResponse(res, {
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Internal server error',
      }, 500);
    }
  }
);

// Audio analysis endpoint
router.post(
  '/audio',
  upload.single('file'),
  validateRequest([]),
  async (req: AuthenticatedRequest, res: Response) => {
    const type = 'audio';
    const correlationId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const file = req.file;
    const userId = req.user?.id;\n    const userToken = extractTokenFromRequest(req);

    logger.info(`[ANALYSIS REQUEST] ${type} analysis started`, {
      correlationId,
      type,
      userId,
      filename: file?.originalname,
      fileSize: file?.size,
    });

    try {
      // Validate file
      if (!file) {
        return res.status(400).json({
          success: false,
          message: 'No file uploaded',
        });
      }

      // Create job with pure UUID (no prefix for database compatibility)
      const jobId = randomUUID();
      logger.info('JOB_CREATED', { jobId, type: 'audio' });
      
      // Create job in database
      let job: { id: string } | null;
      try {
        job = await createAnalysisJob(userId || '', {
          modality: type as AnalysisModality,
          filename: file.originalname,
          mime_type: file.mimetype,
          size_bytes: file.size,
          metadata: {
            originalName: file.originalname,
            mimeType: file.mimetype,
            size: file.size,
          },
        }, jobId); // CRITICAL FIX: Pass jobId to ensure consistency

        logger.info(`[ANALYSIS JOB] Created job ${jobId}`, {
          correlationId,
          jobId,
          type,
        });

        // Send job started event via WebSocket
        if (userId) {
          webSocketManager.sendJobUpdate(userId, jobId, 'processing', 0, 'Job started and queued for processing');
        }
      } catch (dbError) {
        logger.error(`[JOB CREATION FAILED] ${jobId}`, { error: dbError, correlationId });
        return res.status(500).json({
          success: false,
          error: 'Failed to create analysis job' // CRITICAL FIX: Remove job_id from error response to prevent frontend polling for non-existent jobs
        });
      }

    // Send immediate response with job_id only after successful DB creation
      res.status(202).json({
        success: true,
        job_id: jobId,
        status: 'processing',
      });

      // Process in background
      setImmediate(async () => {
        try {
          // Send progress update
          if (userId) {
            sendJobProgress(userId, jobId, 'uploading', 10);
          }

          // Forward to Python service for inference only
          if (!file || !file.buffer) {
            throw new Error('File is required and must have buffer data');
          }
          
          const formData = new FormData();
          formData.append('file', file.buffer, {
            filename: file.originalname,
            contentType: file.mimetype,
          });
          formData.append('job_id', jobId);
          formData.append('user_id', userId || '');

          if (userId) {
            sendJobProgress(userId, jobId, 'analyzing', 30);
          }

          const pythonResponse = await enhancedPythonBridge.request({
            method: 'POST',
            url: `/api/v2/analysis/unified/${type}`,
            data: formData,
            timeout: 300000, // 5 minutes\n            userToken: userToken || undefined
          }) as {
            data: {
              confidence: number;
              is_deepfake: boolean;
              model_name: string;
              model_version: string;
              analysis_data: Record<string, unknown>;
              proof: Record<string, unknown>;
            };
          };

          if (userId) {
            sendJobProgress(userId, jobId, 'processing', 70);
          }

          // Python returns inference-only payload
          const inferenceResult = pythonResponse.data;
          
          // [PYTHON RESULT] - Critical observability point
          logger.info('[PYTHON RESULT]', {
            jobId,
            status: 'success',
            confidence: inferenceResult.confidence,
            is_deepfake: inferenceResult.is_deepfake,
            model_name: inferenceResult.model_name
          });
          
          // Node owns the job lifecycle - ATOMIC GUARD for finalization
          if (job?.id) {
            try {
              await updateAnalysisJobWithResults(job.id, {
                status: 'completed',
                confidence: inferenceResult.confidence,
                is_deepfake: inferenceResult.is_deepfake,
                model_name: inferenceResult.model_name,
                model_version: inferenceResult.model_version,
                analysis_data: inferenceResult.analysis_data,
                proof_json: inferenceResult.proof,
              });
              
              // [JOB FINALIZED] - Critical observability point
              logger.info('[JOB FINALIZED]', {
                jobId: job.id,
                status: 'completed',
                confidence: inferenceResult.confidence
              });
              
            } catch (finalizationError) {
              // FINALIZATION FAILURE - Force fail state
              logger.error('[FINALIZATION FAILURE]', {
                jobId: job.id,
                error: finalizationError
              });
              
              await updateAnalysisJobWithResults(job.id, {
                status: 'failed',
                error_message: 'Finalization failed: ' + String(finalizationError)
              });
              
              throw finalizationError;
            }
          } else {
            logger.error('[NO JOB ID]', { jobId, pythonResponse: 'success' });
          }

          if (userId) {
            sendJobProgress(userId, jobId, 'completed', 100);

            // Send WebSocket event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_COMPLETED',
              jobId,
              timestamp: Date.now(),
              data: {
                status: 'completed',
                confidence: inferenceResult.confidence,
                is_deepfake: inferenceResult.is_deepfake,
                model_name: inferenceResult.model_name,
                model_version: inferenceResult.model_version,
              },
            });
          }

          logger.info(`[ANALYSIS COMPLETED] Job ${jobId} finished successfully`, {
            correlationId,
            jobId,
            type,
            confidence: inferenceResult.confidence,
            is_deepfake: inferenceResult.is_deepfake,
          });

        } catch (error) {
          // Handle analysis error
          const errorMessage = error && typeof error === 'object' && 'response' in error 
            ? ((error as unknown) as { response: { data?: { detail?: string } } }).response?.data?.detail || ((error as unknown) as Error).message || 'Analysis failed'
            : ((error as unknown) as Error).message || 'Analysis failed';
          
          await updateAnalysisJobWithResults(job?.id || '', {
            status: 'failed',
            error_message: errorMessage || 'Analysis failed',
          });

          if (userId) {
            // Send WebSocket error event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_FAILED',
              jobId,
              timestamp: Date.now(),
              data: {
                error: errorMessage,
              },
            });
          }

          logger.error(`[ANALYSIS FAILED] Job ${jobId} failed`, {
            correlationId,
            jobId,
            type,
            error: errorMessage,
          });
        }
      });

    } catch (error) {
      logger.error(`[ANALYSIS ERROR] ${type} analysis failed`, {
        correlationId,
        type,
        error: (error as Error).message,
      });
      
      return errorResponse(res, {
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Internal server error',
      }, 500);
    }
  }
);

// Text analysis endpoint
router.post(
  '/text',
  validateRequest([]),
  async (req: AuthenticatedRequest, res: Response) => {
    const type = 'text';
    const correlationId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const userId = req.user?.id;\n    const userToken = extractTokenFromRequest(req);
    const { text } = req.body;

    logger.info(`[ANALYSIS REQUEST] ${type} analysis started`, {
      correlationId,
      type,
      userId,
      textLength: text?.length || 0,
    });

    try {
      // Validate text input
      if (!text || typeof text !== 'string') {
        return res.status(400).json({
          success: false,
          message: 'Text content is required',
        });
      }

      if (text.trim().length === 0) {
        return res.status(400).json({
          success: false,
          message: 'Text content cannot be empty',
        });
      }

      if (text.length > 10000) {
        return res.status(400).json({
          success: false,
          message: 'Text content too long (maximum 10,000 characters)',
        });
      }

      // Create job with pure UUID (no prefix for database compatibility)
      const jobId = randomUUID();
      logger.info('JOB_CREATED', { jobId, type: 'text' });
      
      // Create job in database
      let job: { id: string } | null;
      try {
        job = await createAnalysisJob(userId || '', {
          modality: 'text' as AnalysisModality,
          filename: 'text-input',
          mime_type: 'text/plain',
          size_bytes: text.length,
          metadata: {
            media_type: 'text'
          },
        }, jobId); // CRITICAL FIX: Pass jobId to ensure consistency

        logger.info(`[ANALYSIS JOB] Created job ${jobId}`, {
          correlationId,
          jobId,
          type,
        });

        // Send job started event via WebSocket
        if (userId) {
          webSocketManager.sendJobUpdate(userId, jobId, 'processing', 0, 'Job started and queued for processing');
        }
      } catch (dbError) {
        logger.error(`[JOB CREATION FAILED] ${jobId}`, { error: dbError, correlationId });
        return res.status(500).json({
          success: false,
          error: 'Failed to create analysis job' // CRITICAL FIX: Remove job_id from error response to prevent frontend polling for non-existent jobs
        });
      }

    // Send immediate response with job_id only after successful DB creation
      res.status(202).json({
        success: true,
        job_id: jobId,
        status: 'processing',
      });

      // Process in background
      setImmediate(async () => {
        try {
          // Send progress update
          if (userId) {
            sendJobProgress(userId, jobId, 'analyzing', 30);
          }

          // Forward to Python service for text analysis
          const pythonResponse = await enhancedPythonBridge.request({
            method: 'POST',
            url: `/upload/text`,
            data: {
              text,
              job_id: jobId,
              user_id: userId || '',
              analyze: true
            },
            timeout: 60000, // 1 minute for text analysis
          }) as {
            data: {
              success: boolean;
              text_length: number;
              word_count: number;
              timestamp: string;
              analysis: {
                is_ai_generated: boolean;
                confidence: number;
                explanation: string;
                model_name: string;
              };
            };
          };

          if (userId) {
            sendJobProgress(userId, jobId, 'processing', 70);
          }

          // Python returns text analysis result
          const textResult = pythonResponse.data;
          
          // [PYTHON RESULT] - Critical observability point
          logger.info('[PYTHON RESULT]', {
            jobId,
            status: 'success',
            confidence: textResult.analysis?.confidence || 0,
            is_ai_generated: textResult.analysis?.is_ai_generated || false,
            model_name: textResult.analysis?.model_name || 'Unknown'
          });
          
          // Node owns job lifecycle - ATOMIC GUARD for finalization
          if (job?.id) {
            try {
              await updateAnalysisJobWithResults(job.id, {
                status: 'completed',
                confidence: textResult.analysis?.confidence || 0,
                is_deepfake: textResult.analysis?.is_ai_generated || false,
                model_name: textResult.analysis?.model_name || 'Unknown',
                model_version: '1.0.0',
                analysis_data: {
                  explanation: textResult.analysis?.explanation || '',
                  text_length: textResult.text_length || 0,
                },
                proof_json: {
                  analysis_type: 'text',
                  timestamp: new Date().toISOString(),
                },
              });
              
              // [JOB FINALIZED] - Critical observability point
              logger.info('[JOB FINALIZED]', {
                jobId: job.id,
                status: 'completed',
                confidence: textResult.analysis?.confidence || 0
              });
              
            } catch (finalizationError) {
              // FINALIZATION FAILURE - Force fail state
              logger.error('[FINALIZATION FAILURE]', {
                jobId: job.id,
                error: finalizationError
              });
              
              await updateAnalysisJobWithResults(job.id, {
                status: 'failed',
                error_message: 'Finalization failed: ' + String(finalizationError)
              });
              
              throw finalizationError;
            }
          } else {
            logger.error('[NO JOB ID]', { jobId, pythonResponse: 'success' });
          }

          if (userId) {
            sendJobProgress(userId, jobId, 'completed', 100);

            // Send WebSocket event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_COMPLETED',
              jobId,
              timestamp: Date.now(),
              data: {
                status: 'completed',
                confidence: textResult.analysis?.confidence || 0,
                is_ai_generated: textResult.analysis?.is_ai_generated || false,
                model_name: textResult.analysis?.model_name || 'Unknown',
                explanation: textResult.analysis?.explanation || '',
              },
            });
          }

          logger.info(`[ANALYSIS COMPLETED] Job ${jobId} finished successfully`, {
            correlationId,
            jobId,
            type,
            confidence: textResult.analysis?.confidence || 0,
            is_ai_generated: textResult.analysis?.is_ai_generated || false,
          });
        } catch (error) {
          // Handle analysis error
          const errorMessage = error && typeof error === 'object' && 'response' in error 
            ? ((error as unknown) as { response: { data?: { detail?: string } } }).response?.data?.detail || ((error as unknown) as Error).message || 'Analysis failed'
            : ((error as unknown) as Error).message || 'Analysis failed';
          
          await updateAnalysisJobWithResults(job?.id || '', {
            status: 'failed',
            error_message: errorMessage || 'Analysis failed',
          });

          if (userId) {
            // Send WebSocket error event
            webSocketManager.sendEventToUser(userId, {
              type: 'JOB_FAILED',
              jobId,
              timestamp: Date.now(),
              data: {
                error: errorMessage,
              },
            });
          }

          logger.error(`[ANALYSIS FAILED] Job ${jobId} failed`, {
            correlationId,
            jobId,
            type,
            error: errorMessage,
          });
        }
      });

    } catch (error) {
      logger.error(`[ANALYSIS ERROR] ${type} analysis failed`, {
        correlationId,
        type,
        error: (error as Error).message,
      });
      
      return errorResponse(res, {
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Internal server error',
      }, 500);
    }
  }
);

// DISABLED: Multimodal analysis endpoint - temporarily deactivated
router.post(
  '/multimodal',
  upload.single('file'),
  validateRequest([]),
  async (req: AuthenticatedRequest, res: Response) => {
    return res.status(410).json({
      success: false,
      message: "Multimodal analysis is temporarily disabled"
    });
  }
);

// Get analysis status
router.get('/status/:id', async (req: Request, res: Response) => {
  try {
    const { id } = req.params;
    
    const result = await enhancedPythonBridge.request({
      method: 'GET',
      url: `/analyze/status/${id}`,
    }) as {
      data: {
        success: boolean;
        data: {
          status: string;
          progress?: number;
          message?: string;
          created_at?: string;
          updated_at?: string;
          completed_at?: string;
          error?: string;
        };
      };
    };

    res.json({
      success: true,
      data: result.data,
    });
  } catch (error) {
    await handleAnalysisError(error, res);
  }
});

// Get analysis status (for polling)
router.get('/status/:id', async (req: Request, res: Response) => {
  try {
    const { id } = req.params;
    const correlationId = getRequestId(req);
    
    logger.info(`[STATUS] Fetching status for job ${id}`, {
      correlationId,
      jobId: id
    });
    
    // Query the database for the job status
    const { data: jobData, error } = await supabaseAdmin
      .from('tasks')
      .select('id, status, progress, started_at, updated_at, error')
      .eq('id', id)
      .single();
    
    if (error || !jobData) {
      logger.error(`[STATUS] Job not found in database`, {
        correlationId,
        jobId: id,
        error: error?.message
      });
      
      return res.status(404).json({
        success: false,
        error: {
          code: 'JOB_NOT_FOUND',
          message: `Analysis job ${id} not found`
        },
        requestId: correlationId,
        timestamp: new Date().toISOString()
      });
    }
    
    const statusResponse = {
      success: true,
      data: {
        status: jobData.status,
        progress: jobData.progress || 0,
        created_at: jobData.started_at,
        updated_at: jobData.updated_at,
        error: jobData.error
      }
    };
    
    logger.info(`[STATUS] Returning job status`, {
      correlationId,
      jobId: id,
      status: statusResponse.data.status
    });
    
    res.json(statusResponse);
  } catch (error) {
    await handleAnalysisError(error, res);
  }
});

// Get analysis results (for polling)
router.get('/results/:jobId', validateJobId, async (req: Request, res: Response) => {
  try {
    const { jobId } = req.params;
    const correlationId = getRequestId(req);
    
    logger.info(`[RESULTS] Fetching results for job ${jobId}`, {
      correlationId,
      jobId
    });
    
    // Query the database for the job using pure UUID
    const { data: jobData, error } = await supabaseAdmin
      .from('tasks')
      .select('*')
      .eq('id', jobId)
      .single();
    
    if (error || !jobData) {
      logger.error(`[RESULTS] Job not found in database`, {
        correlationId,
        jobId,
        error: error?.message
      });
      
      // Return 404 only if job truly doesn't exist
      return res.status(404).json({
        success: false,
        error: 'JOB_NOT_FOUND',
        jobId,
      });
    }

    // Auto-fail stuck jobs (safety guard)
    const maxProcessingTime = 10 * 60 * 1000; // 10 minutes
    const jobAge = Date.now() - new Date(jobData.created_at).getTime();
    const isStuck = jobData.status === 'processing' && jobAge > maxProcessingTime;
    
    if (isStuck) {
      logger.warn(`Auto-failing stuck job: ${jobId}`, {
        status: jobData.status,
        age: jobAge,
        maxAge: maxProcessingTime
      });
      
      // Update to failed status
      await supabaseAdmin
        .from('tasks')
        .update({ 
          status: 'failed',
          error: 'Job automatically failed due to timeout',
          updated_at: new Date().toISOString()
        })
        .eq('id', jobId);
      
      jobData.status = 'failed';
      jobData.error = 'Job automatically failed due to timeout';
    }

    // Return clean response with UUID consistency and field mapping
    logger.info('RESULT_FETCH', { jobId, status: jobData.status });
    return res.json({
      success: true,
      jobId: jobData.id,
      status: jobData.status,
      result: jobData.result ?? null,
      reportCode: jobData.report_code,  // Transform snake_case to camelCase
      createdAt: jobData.created_at,   // Transform snake_case to camelCase
      updatedAt: jobData.updated_at   // Transform snake_case to camelCase
    });
  } catch (error) {
    logger.error('Results endpoint error:', error);
    return res.status(500).json({
      success: false,
      error: 'INTERNAL_SERVER_ERROR',
      message: 'Failed to fetch results'
    });
  }
});

// POST /api/v2/analysis/jobs/:jobId/cancel - Cancel a running job
router.post('/jobs/:jobId/cancel', validateJobId, async (req: AuthenticatedRequest, res: Response) => {
  const { jobId } = req.params;
  const userId = req.user?.id;\n    const userToken = extractTokenFromRequest(req);
  const requestId = req.locals?.requestId || `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

  logger.info('[JOB CANCELLATION] Request received', { jobId, userId, requestId });

  try {
    // Validate authentication
    if (!userId) {
      return res.status(401).json({
        success: false,
        error: {
          code: 'AUTHENTICATION_REQUIRED',
          message: 'Authentication required to cancel jobs'
        }
      });
    }

    // Attempt to cancel job through job manager
    const cancelled = await jobManager.cancelJob(jobId, userId);

    if (!cancelled) {
      // Job might not exist or belong to user
      return res.status(404).json({
        success: false,
        error: {
          code: 'JOB_NOT_FOUND_OR_NOT_CANCELLABLE',
          message: 'Job not found or cannot be cancelled'
        }
      });
    }

    logger.info('[JOB CANCELLATION] Success', { jobId, userId, requestId });

    return res.json({
      success: true,
      message: 'Job cancelled successfully',
      jobId,
      status: 'cancelled'
    });

  } catch (error) {
    logger.error('[JOB CANCELLATION] Error', {
      jobId,
      userId,
      error: error instanceof Error ? error.message : 'Unknown error',
      requestId
    });

    return res.status(500).json({
      success: false,
      error: {
        code: 'CANCELLATION_FAILED',
        message: 'Failed to cancel job. Please try again.'
      }
    });
  }
});

// DEPRECATED: Use /api/v2/results/:jobId instead
// This endpoint kept for backward compatibility only
router.get('/history/:jobId', validateJobId, async (req: Request, res: Response) => {
  logger.warn('[DEPRECATED] /history endpoint used, please migrate to /results', {
    jobId: req.params.jobId,
    userAgent: req.get('User-Agent')
  });
  
  // Redirect to canonical endpoint
  return res.redirect(307, `/api/v2/results/${req.params.jobId}`);
});

export default router;
